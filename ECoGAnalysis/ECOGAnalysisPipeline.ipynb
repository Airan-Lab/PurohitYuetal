{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23282,
     "status": "ok",
     "timestamp": 1708469230267,
     "user": {
      "displayName": "Sedona Noel Ewbank",
      "userId": "06842230844485345849"
     },
     "user_tz": 480
    },
    "id": "BO8rtcIHcOrn",
    "outputId": "7671149d-4941-454a-d3e5-c4943a60b787",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patchesw\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from scipy.stats import f_oneway\n",
    "import pywt\n",
    "import csv\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.lines as mlines\n",
    "from scipy.integrate import simps\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.stats import ttest_ind, kruskal\n",
    "from itertools import combinations\n",
    "from math import sqrt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from sklearn.metrics import auc\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define analysis and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14229,
     "status": "ok",
     "timestamp": 1708469498172,
     "user": {
      "displayName": "Sedona Noel Ewbank",
      "userId": "06842230844485345849"
     },
     "user_tz": 480
    },
    "id": "H3IolQ_Kc_Sj",
    "outputId": "bf0f37a6-fc10-4208-da7d-c95f2dbbf2c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_eeg_processing(group,\n",
    "                         srate,\n",
    "                         epoch_scheme,\n",
    "                         low_cutoff=1,\n",
    "                         high_cutoff=200,\n",
    "                         notch_width=1,\n",
    "                         denoise=True,\n",
    "                         filter_type=\"mne\",\n",
    "                         denoise_extent_threshold=1):\n",
    "    \"\"\"\n",
    "    workhorse function for loading group EEG data and processing (applying bandpass and notch filters, then: \n",
    "            - for single_epoch: applying time-frequency response (tfr) analysis with various baseline \n",
    "            corrections\n",
    "            - for multi_epoch: setting epochs at a few experimentally relevant timepoints and computing power \n",
    "            spectral density in those epochs\n",
    "            \n",
    "    params::\n",
    "    group: dictionary containing keys \"label\" and \"file_paths\"\n",
    "    srate: eeg sampling rate\n",
    "    epoch_scheme: \"single_epoch\" or \"multi_epoch\" analysis\n",
    "    low_cutoff: bandpass filter low end\n",
    "    high_cutoff: bandpass filter high end\n",
    "    notch_width: notch filter width (only used for filter type \"mne\")\n",
    "    denoise: whether to apply wavelet-based denoising\n",
    "    filter_type: type of notch/bandpass filters to apply (can be \"jeff\" or \"mne\")\n",
    "    denoise_extent_threshold: how much denoising is too much, in units of \n",
    "        raw data std deviation? \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    psds=[]\n",
    "    psd_dbs=[]\n",
    "    tfrs=[]\n",
    "    tfrs_logratio=[]\n",
    "    tfrs_mean=[]\n",
    "    tfrs_ratio=[]\n",
    "    tfrs_logratio=[]\n",
    "    tfrs_mean=[]\n",
    "    tfrs_zscore=[]\n",
    "    tfrs_zlogratio=[]\n",
    "    tfrs_percent=[]\n",
    "    \n",
    "    #quality control checks\n",
    "    notch_filter_worked=[]\n",
    "    denoising_shift_hist=[]\n",
    "    denoising_shifts_above_thresh=[]\n",
    "    \n",
    "    for f in range(len(group[\"file_paths\"])):\n",
    "        # Get path to data\n",
    "        print('Loading file:', group[\"file_paths\"][f])\n",
    "        df = pd.read_csv(group[\"file_paths\"][f], usecols=[2], skiprows=5)\n",
    "        raw_data = df.values.squeeze()\n",
    "        raw_data = raw_data[np.newaxis, :]\n",
    "        info = mne.create_info([\"ch1\"], sfreq = srate, ch_types=[\"eeg\"])\n",
    "        raw = mne.io.RawArray(raw_data, info)\n",
    "\n",
    "        denoising_above1sd_change = 0\n",
    "        \n",
    "        # Filter - bandpass at selected low and high cutoffs \n",
    "        if filter_type==\"mne\":\n",
    "            raw.filter(l_freq=low_cutoff, h_freq=high_cutoff)\n",
    "            raw.notch_filter(freqs=(120), picks='eeg', \n",
    "                 method='spectrum_fit', filter_length='10s', notch_widths=notch_width)\n",
    "\n",
    "        if denoise==True:\n",
    "            print(\"\\nDenoising data with Wavelet Decomposition\")\n",
    "            filtered_raw = raw.get_data()[0]\n",
    "            \n",
    "            # Multilevel wavelet decomposition with Daubechies 8 wavelet\n",
    "            # number = granularity, lower number = lower granularity\n",
    "            filtered_raw_decomposed = pywt.wavedec(filtered_raw,'db8', level=5) #chose level 5 for best\n",
    "            \n",
    "            filtered_denoised_decomposed = []\n",
    "            for subband in filtered_raw_decomposed:\n",
    "                med = np.median(np.abs(subband))\n",
    "                tot = np.sum(np.abs(subband))\n",
    "                subband[np.abs(subband)>3*med] = 0\n",
    "                subband *= tot / np.sum(np.abs(subband))\n",
    "                filtered_denoised_decomposed.append(subband)\n",
    "\n",
    "            filtered_denoised_raw = pywt.waverec(filtered_denoised_decomposed,'db8')\n",
    "            \n",
    "            #Calculating how much the data was altered by the wavelet-based denoising\n",
    "            filtered_noisy_sd = np.std(filtered_raw)\n",
    "            length=np.min([len(filtered_denoised_raw),len(filtered_raw)])\n",
    "            denoising_above_thresh_change = np.sum(np.abs(filtered_denoised_raw[0:length] - filtered_raw[0:length]) > denoise_extent_threshold*filtered_noisy_sd)/length\n",
    "            hist, denoising_shift_hist_bins = np.histogram(((filtered_denoised_raw[0:length] - filtered_raw[0:length])/filtered_noisy_sd), bins=30, range=[0,3])\n",
    "            denoising_shift_hist.append(hist)\n",
    "            print(\"Denoising complete; \" + str(denoising_above_thresh_change*100) + \"% of data corrected by >\" + str(denoise_extent_threshold) + \"SD.\\n\")\n",
    "            denoising_shifts_above_thresh.append(denoising_above_thresh_change*100)\n",
    "            raw = mne.io.RawArray(filtered_denoised_raw[np.newaxis, :], info)\n",
    "            \n",
    "        else:\n",
    "            # If denoising is not applied, put some dummy variables in that spot in dictionary output\n",
    "            denoising_shift_hist.append(None)\n",
    "            denoising_shift_hist_bins=None\n",
    "                        \n",
    "        if epoch_scheme==\"single_epoch\":\n",
    "            # Make data into one big epoch for tfr / full session spectrum analysis\n",
    "            events = np.array([[0, 0, 1]])\n",
    "            raw_epoch = mne.Epochs(raw, events, event_id=1, tmin=0, tmax=44*60, #tmax = minutes x seconds\n",
    "                                   baseline=None, preload=True) #tmax = mins*sec\n",
    "            \n",
    "            # Compute and append PSD to dictionary\n",
    "            psd=raw_epoch.compute_psd(fmin=1, fmax=150, method=\"welch\", n_per_seg=int(raw.info[\"sfreq\"]))\n",
    "            psd_freqs=psd.freqs\n",
    "            psd=psd.get_data().squeeze()\n",
    "            psds.append(psd)\n",
    "            psd_db = 10 * np.log10(psd / (1e-6)**2)\n",
    "            psd_dbs.append(psd_db)\n",
    "            \n",
    "            # get indices of 55 hz, 60 hz PSD value\n",
    "            idx_55 = np.argmax(psd_freqs>55)\n",
    "            idx_60 = np.argmax(psd_freqs>60)\n",
    "            \n",
    "            # test if power at 60 Hz is greater than power at 55 Hz\n",
    "            if psd_db[idx_60]-psd_db[idx_55] > 0:\n",
    "                notch_filter_worked.append(False)\n",
    "            else:\n",
    "                notch_filter_worked.append(True)\n",
    "                \n",
    "            count = count+1\n",
    "    \n",
    "            #compute tfr\n",
    "            freqs = np.linspace(1, 55, 55)\n",
    "            power = tfr_multitaper(raw_epoch, freqs=freqs, n_cycles=freqs / 2, use_fft=True,\n",
    "                                   time_bandwidth=2, return_itc=False,\n",
    "                                   decim=100, n_jobs=1)\n",
    "            baseline_inds = [0, 60*5] #baseline as first 5 mins of recording\n",
    "            tfrs.append(power)\n",
    "\n",
    "            # Apply various kinds of baseline normalizations\n",
    "            tfrs_logratio.append(power.copy().apply_baseline(baseline_inds,mode=\"logratio\"))\n",
    "            tfrs_mean.append(power.copy().apply_baseline(baseline_inds,mode=\"mean\"))\n",
    "            tfrs_zlogratio.append(power.copy().apply_baseline(baseline_inds,mode=\"zlogratio\"))\n",
    "            tfrs_zscore.append(power.copy().apply_baseline(baseline_inds,mode=\"zscore\"))\n",
    "            tfrs_percent.append(power.copy().apply_baseline(baseline_inds,mode=\"percent\")*100) #multiply by 100 because its ratios\n",
    "            \n",
    "            print(\"DONE WITH FILE \" + str(count) + \" OF \" + str(len(group[\"file_paths\"])) + \" FOR GROUP \" + group[\"label\"] + \"\\n\\n\")\n",
    "            \n",
    "    if epoch_scheme==\"single_epoch\":\n",
    "        group[\"psd\"]=psds\n",
    "        group[\"psd_db\"]=psd_dbs\n",
    "        group[\"tfr\"]=tfrs\n",
    "        group[\"tfr_logratio\"]=tfrs_logratio\n",
    "        group[\"tfr_mean\"]=tfrs_mean\n",
    "        group[\"tfr_zlogratio\"]=tfrs_zlogratio\n",
    "        group[\"tfr_zscore\"]=tfrs_zscore\n",
    "        group[\"tfr_percent\"]=tfrs_percent\n",
    "        group[\"freqs\"]=psd_freqs\n",
    "        group[\"denoising_shift_hist\"]=denoising_shift_hist\n",
    "        group[\"denoising_shift_hist_bins\"]=denoising_shift_hist_bins\n",
    "        group[\"denoising_shift_above_thresh\"]=denoising_shifts_above_thresh\n",
    "        group[\"notch_filter_worked\"]=notch_filter_worked\n",
    "\n",
    "    group[\"epoch_scheme\"]=epoch_scheme\n",
    "    \n",
    "    return group\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram(groups,vmin,vmax,mode,cmap=None,figW=15,figH=2.5,save=True,output_dir=None):\n",
    "    \"\"\"\n",
    "    Spectrogram plotting function\n",
    "    \n",
    "    params:::\n",
    "    groups: a list of dictionaries\n",
    "    vmin: min value of color plot\n",
    "    vmax: max value of color plot\n",
    "    mode: what data from \"groups\" to use; could be: \"tfr\", \"tfr_db\", \"tfr_logratio\",\"tfr_mean\",\n",
    "        \"tfr_zlogratio\",\"tfr_zscore\",\"tfr_percent\"; \n",
    "        zscore = subtracting the mean of baseline values and dividing by the standard deviation of baseline values,\n",
    "        zlogratio = dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values\n",
    "    cmap: cmap (if not chosen, will end up being rainbow \"jet\" for regular tfr or red/blue for baseline-normed)\n",
    "    figW: fig width\n",
    "    figH: fig height\n",
    "    save: to save or not to save\n",
    "    output_dir: save dir\n",
    "    \"\"\"\n",
    "    plt.rcParams['svg.fonttype'] = 'none' \n",
    "    fig, ax = plt.subplots(1,len(groups),figsize=(figW,figH),dpi=300)\n",
    "    \n",
    "    fig.suptitle(mode)\n",
    "\n",
    "    #set colormap\n",
    "    if cmap==None:\n",
    "        if ((mode==\"tfr\") or (mode==\"tfr_db\")):\n",
    "            cmap=\"jet\"\n",
    "        else:\n",
    "            cmap=\"seismic\"\n",
    "\n",
    "    #set up for db conversion if mode is \"tfr_db\"\n",
    "    if mode==\"tfr_db\":\n",
    "        mode=\"tfr\"\n",
    "        db=True\n",
    "    else:\n",
    "        db=False\n",
    "\n",
    "    for g in range(len(groups)):\n",
    "        if db==False:\n",
    "            logratios=[i.data for i in groups[g][mode]]\n",
    "        elif db==True:\n",
    "            logratios=[10 * np.log10(i.data) for i in groups[g][mode]]\n",
    "        logratio_mean = np.mean(np.array(logratios).squeeze(1),axis=0)\n",
    "        logratios.clear()\n",
    "                \n",
    "        # The actual plotting function\n",
    "        extent = [groups[g][mode][0].times[0]/60, groups[g][mode][0].times[-1]/60, 0, 55]\n",
    "        powerplot = ax[g].imshow(logratio_mean, aspect='auto', origin='lower', cmap=cmap, extent=extent, vmax=vmax, vmin=vmin) \n",
    "        ax[g].set_ylim([0,63]) \n",
    "       \n",
    "        if g==0:\n",
    "            ax[g].plot([5,10],[58,58],linewidth=2.5,color=\"dodgerblue\",label=\"Infusion\")\n",
    "            # Check if 'FUS' is in the group label\n",
    "            if ('-FUS' not in groups[g]['label']) and ('mg/kg' not in groups[g]['label']):\n",
    "                ax[g].plot([7.5,10],[61,61],linewidth=2.5,color=\"black\",label=\"Sonication\")\n",
    "        else:\n",
    "            ax[g].plot([5,10],[58,58],linewidth=2.5,color=\"dodgerblue\")\n",
    "            # Check if 'FUS' is in the group label\n",
    "            if ('-FUS' not in groups[g]['label']) and ('mg/kg' not in groups[g]['label']):\n",
    "                ax[g].plot([7.5,10],[61,61],linewidth=2.5,color=\"black\")\n",
    "        \n",
    "               \n",
    "        ax[g].spines['top'].set_visible(False)\n",
    "        ax[g].axhline(100,color=\"black\",linewidth=0.75)\n",
    "        ax[g].set_xlabel('Time (min)', fontsize=14)\n",
    "        if g == 0:  # This is the first plot\n",
    "            ax[g].set_ylabel('Frequency (Hz)', fontsize=14)\n",
    "        ax[g].set_title(groups[g][\"label\"])\n",
    "        # Adjusting the font sizes\n",
    "        ax[g].tick_params(axis='both', which='major', labelsize=14) # Choose the font size here\n",
    "        \n",
    "        fontsize = 14 #for the colorbar\n",
    "        \n",
    "        #What to call the colorbar lol\n",
    "        if ((mode==\"tfr\") and (db==True)):\n",
    "            cbar_label='Power (dB)'\n",
    "        elif ((mode==\"tfr\") and (db==False)):\n",
    "            cbar_label='Power (μV²/Hz)'\n",
    "        elif mode==\"tfr_zlogratio\":\n",
    "            cbar_label='Z-log ratio to baseline'\n",
    "        elif mode==\"tfr_logratio\":\n",
    "            cbar_label='Log ratio to baseline'\n",
    "        elif mode==\"tfr_zscore\":\n",
    "            cbar_label='Z-score'\n",
    "        elif mode==\"tfr_percent\":\n",
    "            cbar_label='Percent Δ from baseline'\n",
    "        elif mode==\"tfr_mean\":\n",
    "            cbar_label='Δ from baseline mean'\n",
    "        else:\n",
    "            cbar_label=\"\"\n",
    "        if g==len(groups)-1:\n",
    "            #This code creates a space(divider) for colorbar next to each subplot\n",
    "            divider = make_axes_locatable(ax[g])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.15)            \n",
    "            cbar = plt.colorbar(powerplot, cax=cax, label=cbar_label)\n",
    "            cbar.ax.tick_params(labelsize=14)   # set your label size here\n",
    "            cbar.set_label(cbar_label, size=fontsize)\n",
    "        else:  \n",
    "            divider = make_axes_locatable(ax[g])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.15)\n",
    "            cax.axis('off')  # switch off the extra axis for non-last plots\n",
    "    \n",
    "    fig.legend()\n",
    "    plt.tight_layout()\n",
    "    if save==True:\n",
    "        plt.savefig(output_dir + mode + \".svg\", format='svg', dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def moving_average(x, w):\n",
    "    \"\"\"\n",
    "    run of the mill application of np.convolve\n",
    "\n",
    "    params:::\n",
    "    x: 1D data\n",
    "    w: convolving window length\n",
    "    \"\"\"\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fmt(x, pos):\n",
    "    a, b = '{:.2e}'.format(x).split('e')\n",
    "    b = int(b)\n",
    "    return r'${} \\times 10^{{{}}}$'.format(a, b)\n",
    "\n",
    "\n",
    "\n",
    "#Plots PSD over frequency\n",
    "def plot_spectral_density(groups, group_names, mode, time_bins, colors, \n",
    "                          save=False, output_dir=None, ylim_min=None, ylim_max=None):\n",
    "\n",
    "    # Create the figure and axes objects\n",
    "    plt.rcParams['svg.fonttype'] = 'none' \n",
    "    fig, axs = plt.subplots(1, len(time_bins), sharey=True, figsize=(5*len(time_bins),2.5), dpi=300) #horizontal\n",
    "\n",
    "    for ind, (t_start, t_end) in enumerate(time_bins):\n",
    "        for g in range(len(groups)):\n",
    "            logratios=[i.data for i in groups[g][mode]]\n",
    "            logratio_mean = np.mean(np.array(logratios).squeeze(1),axis=0)\n",
    "            logratio_sem = stats.sem(np.array(logratios).squeeze(1), axis=0)\n",
    "            logratios.clear()\n",
    "            freqs = groups[g][mode][0].freqs\n",
    "\n",
    "            time_mask = np.logical_and(groups[g][mode][0].times/60 >= t_start, groups[g][mode][0].times/60 <= t_end)\n",
    "\n",
    "            mean_psd = np.mean(logratio_mean[:, time_mask], axis=1)\n",
    "            sem_psd = np.mean(logratio_sem[:, time_mask], axis=1) \n",
    "\n",
    "            axs[ind].plot(freqs, mean_psd, label=group_names[g], color=colors[g])\n",
    "\n",
    "            # Plot standard error as a shaded region\n",
    "            axs[ind].set_xlabel('Frequency (Hz)')\n",
    "            \n",
    "            # Set y-axis limit if specified\n",
    "            if ylim_min is not None and ylim_max is not None:\n",
    "                axs[ind].set_ylim(ylim_min, ylim_max)\n",
    "            \n",
    "            if mode==\"tfr_zscore\":\n",
    "                axs[ind].set_ylabel('Z-Score')\n",
    "            elif mode==\"tfr_percent\":\n",
    "                axs[ind].set_ylabel('% Change')\n",
    "            elif mode==\"tfr_mean\":\n",
    "                axs[ind].set_ylabel('Δ from baseline mean')\n",
    "            else:\n",
    "                cbar_label=\"\"\n",
    "            axs[ind].set_title(f'{t_start}-{t_end} Mins')\n",
    "    plt.tight_layout()  \n",
    "\n",
    "    if save:\n",
    "        if output_dir is None:\n",
    "            output_dir = os.getcwd()  # Use current working directory if none is provided\n",
    "\n",
    "        fig.savefig(os.path.join(output_dir, 'spectral_density_plot.svg'))\n",
    "\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "#Calculate the AUC for a specific time frame and a specific frequency\n",
    "def calculate_avg_auc(mode, groups, group_titles, low_freq, high_freq, auc, t_start, t_end, print_data=False):\n",
    "    avg_auc_list = []\n",
    "    all_auc_ind = []\n",
    "\n",
    "    for g in range(len(groups)):\n",
    "        time_mask = np.logical_and(groups[g][mode][0].times/60 >= t_start, groups[g][mode][0].times/60 <= t_end)\n",
    "        logratios=[i.data for i in groups[g][mode]]\n",
    "        freqs = groups[g][mode][0].freqs\n",
    "        idx = np.where((freqs >= low_freq) & (freqs <= high_freq))\n",
    "\n",
    "        auc_list = []\n",
    "        for i in range(len(logratios)):\n",
    "            logratio_data = logratios[i].reshape(-1, logratios[i].shape[-1])\n",
    "            data_psd = np.mean(logratio_data[:, time_mask], axis=1)\n",
    "            ind = auc(freqs[idx], data_psd[idx])  #x, y\n",
    "            auc_list.append(ind)\n",
    "                       \n",
    "        avg_auc = np.mean(auc_list)\n",
    "        avg_auc_list.append(avg_auc)\n",
    "        all_auc_ind.append(auc_list)\n",
    "        \n",
    "        if print_data == True: \n",
    "            print(f\"group = {auc_list}\" )\n",
    "\n",
    "    return avg_auc_list, all_auc_ind\n",
    "\n",
    "\n",
    "def plot_auc(groups, avg_aucs, all_aucs, group_titles, colors, save=False, output_dir=None):\n",
    "    plt.rcParams['svg.fonttype'] = 'none' \n",
    "    \n",
    "    x_pos = np.arange(len(groups))\n",
    "\n",
    "    for i in range(len(groups)):\n",
    "        # Add color to the bar\n",
    "        plt.bar(x_pos[i], avg_aucs[i], align='center', color=colors[i], alpha=0.7)\n",
    "\n",
    "        # Overlay individual datapoints\n",
    "        y = all_aucs[i]\n",
    "        x = [i] * len(y)  # All x-values for a group are the same.\n",
    "        plt.scatter(x, y, color=colors[i], alpha=0.5)  # Add color to the scatterplot points\n",
    "\n",
    "    # Add labels / title and show the plot\n",
    "    plt.xticks(x_pos, group_titles)\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(f'AUC from {t_start}-{t_end} mins for {low_freq}-{high_freq} Hz')\n",
    "\n",
    "    if save==True:\n",
    "        plt.savefig(output_dir + str(t_start) + \"to\" + str(t_end) + \"mins_at_\" + str(low_freq) + str(high_freq) + \"Hz\" + \".svg\", format='svg', dpi=500)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def run_stats(groups, group_titles):\n",
    "    # Collect results in a DataFrame\n",
    "    col_names = [\"Group1\", \"Group2\", \"Mean Diff\", \"p-adj\", \"Lower\", \"Upper\", \"Reject Null\"]\n",
    "    results_df = pd.DataFrame(columns = [\"Statistic\", \"P-value\"])\n",
    "        \n",
    "    # Perform one-way ANOVA\n",
    "    stat, pval = stats.f_oneway(*groups)\n",
    "    print('ANOVA statistic:', stat)\n",
    "    print('p-value:', pval)\n",
    "    results_df.loc[0] = [stat, pval]\n",
    "\n",
    "    # Perform and print Tukey HSD results\n",
    "    data_all = np.concatenate(groups)\n",
    "    group_labels = []\n",
    "    for i, group in enumerate(groups):\n",
    "        group_labels += [group_titles[i]] * len(group)\n",
    "    tukey_results = pairwise_tukeyhsd(data_all, group_labels)\n",
    "    print(tukey_results)\n",
    "    summary = tukey_results.summary()\n",
    "    summary_df = pd.DataFrame(summary[1:], columns=col_names)\n",
    "    \n",
    "    stats_df = pd.concat([results_df, summary_df], axis=1, keys=['ANOVA', 'Tukey HSD'])\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "def calculate_hedges_g(data1, data2):\n",
    "    # get means\n",
    "    mean1, mean2 = np.mean(data1), np.mean(data2)\n",
    "    \n",
    "    # Corrected pooled standard deviation calculation\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "    sd1, sd2 = np.std(data1, ddof=1), np.std(data2, ddof=1)\n",
    "    s_pooled = sqrt(((n1 - 1) * sd1 ** 2 + (n2 - 1) * sd2 ** 2) / (n1 + n2 - 2))\n",
    "    \n",
    "    # Delta calculation\n",
    "    delta = (mean1 - mean2) / s_pooled\n",
    "    \n",
    "    # Correcting factor calculation\n",
    "    j = 1 - 3 / (4 * (n1 + n2) - 9)\n",
    "    \n",
    "    # Hedges' g\n",
    "    g = j * delta\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Get info for all of the functions using \"help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(group_eeg_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: for running full notebook all at once, set paths and options here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all\n",
    "filter_type=\"mne\"\n",
    "denoise=True \n",
    "save=True\n",
    "pickle_save_dir = \"./pickle/\"\n",
    "\n",
    "# mPFC\n",
    "mPFC_uncaging_figures_dir=\"./output/mPFC_uncaging/\"\n",
    "mPFC_dr_figures_dir=\"./output/mPFC_DR/\"\n",
    "\n",
    "# RSC\n",
    "RSC_uncaging_figures_dir=\"./output/RSC_uncaging/\"\n",
    "RSC_dr_figures_dir=\"./output/RSC_DR/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# mPFC Uncaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dictionaries for depositing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1940,
     "status": "ok",
     "timestamp": 1708469236704,
     "user": {
      "displayName": "Sedona Noel Ewbank",
      "userId": "06842230844485345849"
     },
     "user_tz": 480
    },
    "id": "6iBYM4cJcvaw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory where the data are stored\n",
    "root_directory=\"./SourceData\"\n",
    "\n",
    "# Set up the dictionaries where we will be dumping all data, labels, calculations, etc\n",
    "LipKFUS = {\"directory\": root_directory+\"/mPFC/LipKFUS/\"}\n",
    "LipKnoFUS = {\"directory\": root_directory+\"/mPFC/LipKonly/\"}\n",
    "FreeKnoFUS = {\"directory\": root_directory+\"/mPFC/Ketamine/\"}\n",
    "SalFUS = {\"directory\": root_directory+\"/mPFC/SalineFUS/\"}\n",
    "\n",
    "# Add labels\n",
    "LipKFUS[\"label\"]=\"LipK +FUS\"\n",
    "LipKnoFUS[\"label\"]=\"LipK -FUS\" \n",
    "FreeKnoFUS[\"label\"]=\"FreeK -FUS\" \n",
    "SalFUS[\"label\"]=\"Sal +FUS\" \n",
    "\n",
    "# Add filepaths\n",
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "for g in range(len(groups)):\n",
    "    file_paths = []\n",
    "    data_dir = groups[g][\"directory\"]\n",
    "    data_files = [i for i in os.listdir(data_dir) if \"._\" not in i]\n",
    "    \n",
    "    for file in data_files:\n",
    "        full_path = os.path.join(data_dir, file)  # Create full path to every csv file\n",
    "        file_paths.append(full_path)  # Add each csv file path to list\n",
    "\n",
    "    groups[g][\"file_paths\"] = file_paths  # Save paths in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Preprocess for time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iterate through groups to apply bandpass and notch filters, compute power spectral density, compute time frequency representation, and compute\n",
    "filter_type=\"mne\"\n",
    "denoise=True\n",
    "srate = 1000.0\n",
    "low_cutoff = 1\n",
    "high_cutoff = 200\n",
    "notch_width = 1\n",
    "thresh=1\n",
    "\n",
    "for g in range(len(groups)):\n",
    "    groups[g] = group_eeg_processing(groups[g],\n",
    "                                 srate,\n",
    "                                 \"single_epoch\",\n",
    "                                 low_cutoff=low_cutoff,\n",
    "                                 high_cutoff=high_cutoff,\n",
    "                                 notch_width=notch_width,\n",
    "                                 denoise=denoise,\n",
    "                                 filter_type=filter_type,\n",
    "                                 denoise_extent_threshold=thresh)\n",
    "    \n",
    "    print(\"DONE WITH GROUP \" + str(g+1) + \" OF \" + str(len(groups)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# filename = pickle_dir + 'mPFC_SalFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     SalFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 1 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'mPFC_LipKnoFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     LipKnoFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 2 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'mPFC_LipKFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     LipKFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 3 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'mPFC_FreeKnoFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeKnoFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 4 of 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full session spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "\n",
    "output_dir=mPFC_uncaging_figures_dir\n",
    "save = False\n",
    "figW=12\n",
    "figH=2.5\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10**-9.5,10**-7.6,\n",
    "#                  \"tfr\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10 * np.log10(10**-10),10 * np.log10(10**-7),\n",
    "#                  \"tfr_db\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1,1,\n",
    "#                  \"tfr_logratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1.5,1.5,\n",
    "#                  \"tfr_zlogratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "plot_spectrogram(groups,\n",
    "                 -200,200,\n",
    "                 \"tfr_percent\",\n",
    "                 figW=figW,figH=figH,save=save,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Change over Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir=mPFC_uncaging_figures_dir\n",
    "save = False\n",
    "decim = 10\n",
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "group_names = ['Sal FUS(+)', 'Ket FUS(-)', 'SonoKet FUS(-)', 'SonoKet FUS(+)'] \n",
    "colors = ['darkgrey', 'black', 'mistyrose', 'indianred']\n",
    "time_bins = [(7.5, 10), (10, 25), (25, 45)]\n",
    "mode = \"tfr_percent\"\n",
    "\n",
    "plot_spectral_density(groups=groups, group_names=group_names, mode=mode, time_bins=time_bins, colors=colors, save=save, output_dir=output_dir, ylim_min=-19, ylim_max=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the Curve and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = mPFC_uncaging_figures_dir\n",
    "print_data=False\n",
    "mode = \"tfr_percent\"\n",
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "group_titles = [\"SalFUS\", \"FreeKnoFUS\", \"LipKnoFUS\", \"LipKFUS\"] \n",
    "colors = ['darkgrey', 'black', 'mistyrose', 'indianred']\n",
    "time_bins = [(7.5, 10), (10, 25), (25, 45)]\n",
    "freq_bins = [(1,4),(4,8),(8,15),(15,25),(25,55)]\n",
    "\n",
    "all_stats = []\n",
    "all_hedges = []\n",
    "\n",
    "for t_start, t_end in time_bins:\n",
    "    for low_freq, high_freq in freq_bins:\n",
    "        avg_aucs, all_aucs = calculate_avg_auc(mode, groups, group_titles, low_freq, high_freq, auc, t_start, t_end, print_data)       \n",
    "        stats_df = run_stats(all_aucs, group_titles)\n",
    "\n",
    "        # Add the time_bin and freq_bin info to the DataFrame\n",
    "        stats_df['time_bin_start'] = t_start\n",
    "        stats_df['time_bin_end'] = t_end\n",
    "        stats_df['freq_bin_low'] = low_freq\n",
    "        stats_df['freq_bin_high'] = high_freq\n",
    "        all_stats.append(stats_df)\n",
    "        \n",
    "        group_pairs_ind = list(itertools.combinations(range(len(all_aucs)), 2))    \n",
    "        for i, j in group_pairs_ind:\n",
    "            hedges_g = calculate_hedges_g(all_aucs[i], all_aucs[j])\n",
    "            print(f\"Hedges' g for groups {i} and {j} at time bin {t_start}-{t_end} and freq bin {low_freq}-{high_freq}: {hedges_g}\")\n",
    "            # create a DataFrame to hold the Hedges' g results and store in the all_hedges_dfs list\n",
    "            df_hedges = pd.DataFrame({\n",
    "                'Group1': [group_titles[i]],\n",
    "                'Group2': [group_titles[j]],\n",
    "                'Hedges_g': [hedges_g],\n",
    "                'time_bin_start': [t_start],\n",
    "                'time_bin_end': [t_end],\n",
    "                'freq_bin_low': [low_freq],\n",
    "                'freq_bin_high': [high_freq]\n",
    "            })\n",
    "            all_hedges.append(df_hedges)    \n",
    "        \n",
    "        plot_auc(groups, avg_aucs, all_aucs, group_titles, colors, save=False, output_dir=output_dir)\n",
    "\n",
    "# all_stats_combined = pd.concat(all_stats, ignore_index=True)\n",
    "# all_hedges_combined = pd.concat(all_hedges, ignore_index=True)\n",
    "# all_stats_combined.to_csv(output_dir + 'stats.csv', index=False)\n",
    "# all_hedges_combined.to_csv(output_dir + \"hedges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# with open(pickle_dir+'mPFC_SalFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(SalFUS, file)\n",
    "# with open(pickle_dir+'mPFC_LipKnoFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(LipKnoFUS, file)\n",
    "# with open(pickle_dir+'mPFC_LipKFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(LipKFUS, file)\n",
    "# with open(pickle_dir+'mPFC_FreeKnoFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeKnoFUS, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mPFC Dose-response - full session analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dictionaries for depositing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory where the data are stored\n",
    "root_directory=\"./SourceData\"\n",
    "\n",
    "# Set up the dictionaries where we will be dumping all data, labels, calculations, etc\n",
    "FreeK0500 = {\"directory\": root_directory+\"/DoseResponse_mPFC/Ket_inf0.5/\"}\n",
    "FreeK0750 = {\"directory\": root_directory+\"/DoseResponse_mPFC/Ket_inf0.75/\"}\n",
    "FreeK1000 = {\"directory\": root_directory+\"/DoseResponse_mPFC/Ket_inf1/\"}\n",
    "FreeK1500 = {\"directory\": root_directory+\"/DoseResponse_mPFC/Ket_inf1.5/\"}\n",
    "\n",
    "# Add labels\n",
    "FreeK0500[\"label\"]=\"0.5 mg/kg Ket\"\n",
    "FreeK0750[\"label\"]=\"0.75 mg/kg Ket\"\n",
    "FreeK1000[\"label\"]=\"1.0 mg/kg Ket\"\n",
    "FreeK1500[\"label\"]=\"1.5 mg/kg Ket\"\n",
    "\n",
    "# Add filepaths\n",
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "for g in range(len(groups)):\n",
    "    file_paths = []\n",
    "    data_dir = groups[g][\"directory\"]\n",
    "    data_files = [i for i in os.listdir(data_dir) if \"._\" not in i]\n",
    "    \n",
    "    for file in data_files:\n",
    "        full_path = os.path.join(data_dir, file)  # Create full path to every csv file\n",
    "        file_paths.append(full_path)  # Add each csv file path to list\n",
    "\n",
    "    groups[g][\"file_paths\"] = file_paths  # Save paths in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Preprocess for time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iterate through groups to apply bandpass and notch filters, compute power spectral density, compute time frequency representation, and compute\n",
    "filter_type=\"mne\" \n",
    "denoise=True\n",
    "srate = 1000.0\n",
    "low_cutoff = 1\n",
    "high_cutoff = 200\n",
    "notch_width = 1\n",
    "thresh=1\n",
    "\n",
    "for g in range(len(groups)):\n",
    "    groups[g] = group_eeg_processing(groups[g],\n",
    "                                 srate,\n",
    "                                 \"single_epoch\",\n",
    "                                 low_cutoff=low_cutoff,\n",
    "                                 high_cutoff=high_cutoff,\n",
    "                                 notch_width=notch_width,\n",
    "                                 denoise=denoise,\n",
    "                                 filter_type=filter_type,\n",
    "                                 denoise_extent_threshold=thresh)\n",
    "    print(\"DONE WITH GROUP \" + str(g+1) + \" OF \" + str(len(groups)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# filename = pickle_dir + 'mPFC_FreeK0500.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK0500 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 1 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'mPFC_FreeK0750.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK0750 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 2 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'mPFC_FreeK1000.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK1000 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 3 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'mPFC_FreeK1500.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK1500 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 4 of 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full session spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "output_dir=mPFC_dr_figures_dir\n",
    "save=False\n",
    "figW=12\n",
    "figH=2.5\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10**-9.5,10**-7.6,\n",
    "#                  \"tfr\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10 * np.log10(10**-10),10 * np.log10(10**-7),\n",
    "#                  \"tfr_db\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1,1,\n",
    "#                  \"tfr_logratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1.5,1.5,\n",
    "#                  \"tfr_zlogratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "plot_spectrogram(groups,\n",
    "                 -200,200,\n",
    "                 \"tfr_percent\",\n",
    "                 figW=figW,figH=figH,save=save,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Change over Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir=mPFC_dr_figures_dir\n",
    "save=False\n",
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "group_names = ['0.5 mg/kg', '0.75 mg/kg', '1.0 mg/kg', '1.5 mg/kg'] \n",
    "colors = ['lightgrey', 'darkgrey', 'dimgray', 'black']\n",
    "mode = \"tfr_percent\"\n",
    "time_bins = [(7.5, 10), (10, 25), (25, 45)]\n",
    "decim = 10\n",
    "\n",
    "plot_spectral_density(groups=groups, group_names=group_names, mode=\"tfr_percent\", time_bins=time_bins, colors=colors, save=save, output_dir=output_dir, ylim_min=-40, ylim_max=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the Curve and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir=mPFC_dr_figures_dir\n",
    "print_data=False\n",
    "mode = \"tfr_percent\"\n",
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "group_titles = ['0.5 mg/kg', '0.75 mg/kg', '1.0 mg/kg', '1.5 mg/kg'] \n",
    "colors = ['lightgrey', 'darkgrey', 'dimgray', 'black']\n",
    "time_bins = [(7.5, 10),(10, 25),(25, 45)]\n",
    "freq_bins = [(1,4),(4,8),(8,15),(15,25),(25,55)]\n",
    "\n",
    "all_stats = []\n",
    "all_hedges = []\n",
    "\n",
    "for t_start, t_end in time_bins:\n",
    "    for low_freq, high_freq in freq_bins:\n",
    "        avg_aucs, all_aucs = calculate_avg_auc(mode, groups, group_titles, low_freq, high_freq, auc, t_start, t_end, print_data)       \n",
    "        stats_df = run_stats(all_aucs, group_titles)\n",
    "\n",
    "        # Add the time_bin and freq_bin info to the DataFrame\n",
    "        stats_df['time_bin_start'] = t_start\n",
    "        stats_df['time_bin_end'] = t_end\n",
    "        stats_df['freq_bin_low'] = low_freq\n",
    "        stats_df['freq_bin_high'] = high_freq\n",
    "        all_stats.append(stats_df)\n",
    "        \n",
    "        group_pairs_ind = list(itertools.combinations(range(len(all_aucs)), 2))    \n",
    "        for i, j in group_pairs_ind:\n",
    "            hedges_g = calculate_hedges_g(all_aucs[i], all_aucs[j])\n",
    "            print(f\"Hedges' g for groups {i} and {j} at time bin {t_start}-{t_end} and freq bin {low_freq}-{high_freq}: {hedges_g}\")\n",
    "            # create a DataFrame to hold the Hedges' g results and store in the all_hedges_dfs list\n",
    "            df_hedges = pd.DataFrame({\n",
    "                'Group1': [group_titles[i]],\n",
    "                'Group2': [group_titles[j]],\n",
    "                'Hedges_g': [hedges_g],\n",
    "                'time_bin_start': [t_start],\n",
    "                'time_bin_end': [t_end],\n",
    "                'freq_bin_low': [low_freq],\n",
    "                'freq_bin_high': [high_freq]\n",
    "            })\n",
    "            all_hedges.append(df_hedges)    \n",
    "        \n",
    "        plot_auc(groups, avg_aucs, all_aucs, group_titles, colors, save=False, output_dir=output_dir)\n",
    "\n",
    "# all_stats_combined = pd.concat(all_stats, ignore_index=True)\n",
    "# all_hedges_combined = pd.concat(all_hedges, ignore_index=True)\n",
    "# all_stats_combined.to_csv(output_dir + 'stats.csv', index=False)\n",
    "# all_hedges_combined.to_csv(output_dir + \"hedges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# with open(pickle_dir+'mPFC_FreeK0500.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK0500, file)\n",
    "# with open(pickle_dir+'mPFC_FreeK0750.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK0750, file)\n",
    "# with open(pickle_dir+'mPFC_FreeK1000.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK1000, file)\n",
    "# with open(pickle_dir+'mPFC_FreeK1500.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK1500, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrosplenial Cortex Uncaging - full session "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dictionaries for depositing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory where the data are stored\n",
    "root_directory=\"./SourceData\"\n",
    "\n",
    "# Set up the dictionaries where we will be dumping all data, labels, calculations, etc\n",
    "LipKFUS = {\"directory\": root_directory+\"/RsC/LipKFUS/\"}\n",
    "LipKnoFUS = {\"directory\": root_directory+\"/RsC/LipKonly/\"}\n",
    "FreeKnoFUS = {\"directory\": root_directory+\"/RsC/Ketamine/\"}\n",
    "SalFUS = {\"directory\": root_directory+\"/RsC/SalineFUS/\"}\n",
    "\n",
    "# Add labels\n",
    "LipKFUS[\"label\"]=\"LipK +FUS\"\n",
    "LipKnoFUS[\"label\"]=\"LipK -FUS\" \n",
    "FreeKnoFUS[\"label\"]=\"FreeK -FUS\" \n",
    "SalFUS[\"label\"]=\"Sal +FUS\" \n",
    "\n",
    "# Add filepaths\n",
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "for g in range(len(groups)):\n",
    "    file_paths = []\n",
    "    data_dir = groups[g][\"directory\"]\n",
    "    data_files = [i for i in os.listdir(data_dir) if \"._\" not in i]\n",
    "    \n",
    "    for file in data_files:\n",
    "        full_path = os.path.join(data_dir, file)  # Create full path to every csv file\n",
    "        file_paths.append(full_path)  # Add each csv file path to list\n",
    "\n",
    "    groups[g][\"file_paths\"] = file_paths  # Save paths in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Preprocess for time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iterate through groups to apply bandpass and notch filters, compute power spectral density, compute time frequency representation, and compute\n",
    "filter_type=\"mne\"\n",
    "denoise=True\n",
    "srate = 1000.0\n",
    "low_cutoff = 1\n",
    "high_cutoff = 200\n",
    "notch_width = 1\n",
    "thresh=1\n",
    "\n",
    "for g in range(len(groups)):\n",
    "    groups[g] = group_eeg_processing(groups[g],\n",
    "                                 srate,\n",
    "                                 \"single_epoch\",\n",
    "                                 low_cutoff=low_cutoff,\n",
    "                                 high_cutoff=high_cutoff,\n",
    "                                 notch_width=notch_width,\n",
    "                                 denoise=denoise,\n",
    "                                 filter_type=filter_type,\n",
    "                                 denoise_extent_threshold=thresh)\n",
    "    print(\"DONE WITH GROUP \" + str(g+1) + \" OF \" + str(len(groups)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# filename = pickle_dir + 'RSC_SalFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     SalFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 1 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'RSC_LipKnoFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     LipKnoFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 2 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'RSC_LipKFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     LipKFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 3 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'RSC_FreeKnoFUS_single-epoch.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeKnoFUS = pickle.load(file)\n",
    "#     print(\"Done loading pickle 4 of 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full session spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "output_dir=RSC_uncaging_figures_dir\n",
    "save=False\n",
    "figW=12\n",
    "figH=2.5\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10**-9.5,10**-7.6,\n",
    "#                  \"tfr\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10 * np.log10(10**-10),10 * np.log10(10**-7),\n",
    "#                  \"tfr_db\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1,1,\n",
    "#                  \"tfr_logratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1.5,1.5,\n",
    "#                  \"tfr_zlogratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "plot_spectrogram(groups,\n",
    "                 -200,200,\n",
    "                 \"tfr_percent\",\n",
    "                 figW=figW,figH=figH,save=save,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Change over Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir=RSC_uncaging_figures_dir\n",
    "save=False\n",
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "group_names = ['Sal FUS(+)', 'Ket FUS(-)', 'SonoKet FUS(-)', 'SonoKet FUS(+)'] \n",
    "colors = ['darkgrey', 'black', 'lightsteelblue', 'cornflowerblue']\n",
    "mode = \"tfr_percent\"\n",
    "decim = 10\n",
    "time_bins = [(7.5, 10), (10, 25), (25, 45)]  \n",
    "\n",
    "plot_spectral_density(groups=groups, group_names=group_names, mode=mode, time_bins=time_bins, colors=colors, save=save, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Area Under the Curve and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = RSC_uncaging_figures_dir\n",
    "print_data=False\n",
    "mode = \"tfr_percent\"\n",
    "groups = [SalFUS, FreeKnoFUS, LipKnoFUS, LipKFUS]\n",
    "group_titles = [\"SalFUS\", \"FreeKnoFUS\", \"LipKnoFUS\", \"LipKFUS\"] \n",
    "colors = ['darkgrey', 'black', 'lightsteelblue', 'cornflowerblue']\n",
    "time_bins = [(7.5, 10), (10, 25), (25, 45)]\n",
    "freq_bins = [(1,4), (4,8), (8,15), (15,25), (25,55)]\n",
    "\n",
    "all_stats = []\n",
    "all_hedges = []\n",
    "\n",
    "for t_start, t_end in time_bins:\n",
    "    for low_freq, high_freq in freq_bins:\n",
    "        avg_aucs, all_aucs = calculate_avg_auc(mode, groups, group_titles, low_freq, high_freq, auc, t_start, t_end, print_data)       \n",
    "        stats_df = run_stats(all_aucs, group_titles)\n",
    "\n",
    "        # Add the time_bin and freq_bin info to the DataFrame\n",
    "        stats_df['time_bin_start'] = t_start\n",
    "        stats_df['time_bin_end'] = t_end\n",
    "        stats_df['freq_bin_low'] = low_freq\n",
    "        stats_df['freq_bin_high'] = high_freq\n",
    "        all_stats.append(stats_df)\n",
    "        \n",
    "        group_pairs_ind = list(itertools.combinations(range(len(all_aucs)), 2))    \n",
    "        for i, j in group_pairs_ind:\n",
    "            hedges_g = calculate_hedges_g(all_aucs[i], all_aucs[j])\n",
    "            print(f\"Hedges' g for groups {i} and {j} at time bin {t_start}-{t_end} and freq bin {low_freq}-{high_freq}: {hedges_g}\")\n",
    "            # create a DataFrame to hold the Hedges' g results and store in the all_hedges_dfs list\n",
    "            df_hedges = pd.DataFrame({\n",
    "                'Group1': [group_titles[i]],\n",
    "                'Group2': [group_titles[j]],\n",
    "                'Hedges_g': [hedges_g],\n",
    "                'time_bin_start': [t_start],\n",
    "                'time_bin_end': [t_end],\n",
    "                'freq_bin_low': [low_freq],\n",
    "                'freq_bin_high': [high_freq]\n",
    "            })\n",
    "            all_hedges.append(df_hedges)    \n",
    "        \n",
    "        plot_auc(groups, avg_aucs, all_aucs, group_titles, colors, save=False, output_dir=output_dir)\n",
    "\n",
    "# all_stats_combined = pd.concat(all_stats, ignore_index=True)\n",
    "# all_hedges_combined = pd.concat(all_hedges, ignore_index=True)\n",
    "# all_stats_combined.to_csv(output_dir + 'stats.csv', index=False)\n",
    "# all_hedges_combined.to_csv(output_dir + \"hedges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# with open(pickle_dir+'RSC_SalFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(SalFUS, file)\n",
    "# with open(pickle_dir+'RSC_LipKnoFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(LipKnoFUS, file)\n",
    "# with open(pickle_dir+'RSC_LipKFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(LipKFUS, file)\n",
    "# with open(pickle_dir+'RSC_FreeKnoFUS_single-epoch.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeKnoFUS, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RsC Dose Response - full session analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dictionaries for depositing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory where the data are stored\n",
    "root_directory=\"./SourceData\"\n",
    "\n",
    "# Set up the dictionaries where we will be dumping all data, labels, calculations, etc\n",
    "FreeK0500 = {\"directory\": root_directory+\"/DoseResponse_RSC/Ket0.5/\"}\n",
    "FreeK0750 = {\"directory\": root_directory+\"/DoseResponse_RSC/Ket0.75/\"}\n",
    "FreeK1000 = {\"directory\": root_directory+\"/DoseResponse_RSC/Ket1/\"}\n",
    "FreeK1500 = {\"directory\": root_directory+\"/DoseResponse_RSC/Ket1.5/\"}\n",
    "\n",
    "# Add labels\n",
    "FreeK0500[\"label\"]=\"0.5 mg/kg Ket\"\n",
    "FreeK0750[\"label\"]=\"0.75 mg/kg Ket\"\n",
    "FreeK1000[\"label\"]=\"1.0 mg/kg Ket\"\n",
    "FreeK1500[\"label\"]=\"1.5 mg/kg Ket\"\n",
    "\n",
    "# Add filepaths\n",
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "\n",
    "for g in range(len(groups)):\n",
    "    file_paths = []\n",
    "    data_dir = groups[g][\"directory\"]\n",
    "    data_files = [i for i in os.listdir(data_dir) if \"._\" not in i]\n",
    "    \n",
    "    for file in data_files:\n",
    "        full_path = os.path.join(data_dir, file)  # Create full path to every csv file\n",
    "        file_paths.append(full_path)  # Add each csv file path to list\n",
    "\n",
    "    groups[g][\"file_paths\"] = file_paths  # Save paths in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Preprocess for time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iterate through groups to apply bandpass and notch filters, compute power spectral density, compute time frequency representation, and compute\n",
    "filter_type=\"mne\"\n",
    "denoise=denoise\n",
    "srate = 1000.0\n",
    "low_cutoff = 1\n",
    "high_cutoff = 200\n",
    "notch_width = 1\n",
    "thresh=1\n",
    "\n",
    "for g in range(len(groups)):\n",
    "    groups[g] = group_eeg_processing(groups[g],\n",
    "                                 srate,\n",
    "                                 \"single_epoch\",\n",
    "                                 low_cutoff=low_cutoff,\n",
    "                                 high_cutoff=high_cutoff,\n",
    "                                 notch_width=notch_width,\n",
    "                                 denoise=denoise,\n",
    "                                 filter_type=filter_type,\n",
    "                                 denoise_extent_threshold=thresh)\n",
    "    print(\"DONE WITH GROUP \" + str(g+1) + \" OF \" + str(len(groups)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# filename = pickle_dir + 'RSC_FreeK0500.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK0500 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 1 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'RSC_FreeK0750.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK0750 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 2 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'RSC_FreeK1000.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK1000 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 3 of 4\")\n",
    "    \n",
    "# filename = pickle_dir + 'RSC_FreeK1500.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     FreeK1500 = pickle.load(file)\n",
    "#     print(\"Done loading pickle 4 of 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full session spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "output_dir=RSC_dr_figures_dir\n",
    "save=False\n",
    "figW=12\n",
    "figH=2.5\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10**-9.5,10**-7.6,\n",
    "#                  \"tfr\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  10 * np.log10(10**-10),10 * np.log10(10**-7),\n",
    "#                  \"tfr_db\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1,1,\n",
    "#                  \"tfr_logratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "# plot_spectrogram(groups,\n",
    "#                  -1.5,1.5,\n",
    "#                  \"tfr_zlogratio\",\n",
    "#                  figW=figW,figH=figH,save=save,output_dir=output_dir)\n",
    "\n",
    "plot_spectrogram(groups,\n",
    "                 -200,200,\n",
    "                 \"tfr_percent\",\n",
    "                 figW=figW,figH=figH,save=save,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Change over Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir=RSC_dr_figures_dir\n",
    "save=False\n",
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "group_names = ['0.5 mg/kg', '0.75 mg/kg', '1.0 mg/kg', '1.5 mg/kg'] \n",
    "colors = ['lightgrey', 'darkgrey', 'dimgray', 'black']\n",
    "mode = \"tfr_percent\"\n",
    "decim = 10\n",
    "time_bins = [(7.5, 10), (10, 25), (25,45)]  \n",
    "plot_spectral_density(groups=groups, group_names=group_names, mode=\"tfr_percent\", time_bins=time_bins, colors=colors, save=save, output_dir=output_dir, ylim_min=-40, ylim_max=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the Curve and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir=RSC_dr_figures_dir\n",
    "print_data=False\n",
    "mode = \"tfr_percent\"\n",
    "groups = [FreeK0500, FreeK0750, FreeK1000, FreeK1500]\n",
    "group_titles = ['0.5 mg/kg', '0.75 mg/kg', '1.0 mg/kg', '1.5 mg/kg'] \n",
    "colors = ['lightgrey', 'darkgrey', 'dimgray', 'black']\n",
    "time_bins = [(7.5, 10),(10, 25),(25, 45)]\n",
    "freq_bins = [(1,4),(4,8),(8,15),(15,25),(25,55)]\n",
    "\n",
    "all_stats = []\n",
    "all_hedges = []\n",
    "\n",
    "for t_start, t_end in time_bins:\n",
    "    for low_freq, high_freq in freq_bins:\n",
    "        avg_aucs, all_aucs = calculate_avg_auc(mode, groups, group_titles, low_freq, high_freq, auc, t_start, t_end, print_data)       \n",
    "        stats_df = run_stats(all_aucs, group_titles)\n",
    "\n",
    "        # Add the time_bin and freq_bin info to the DataFrame\n",
    "        stats_df['time_bin_start'] = t_start\n",
    "        stats_df['time_bin_end'] = t_end\n",
    "        stats_df['freq_bin_low'] = low_freq\n",
    "        stats_df['freq_bin_high'] = high_freq\n",
    "        all_stats.append(stats_df)\n",
    "        \n",
    "        group_pairs_ind = list(itertools.combinations(range(len(all_aucs)), 2))    \n",
    "        for i, j in group_pairs_ind:\n",
    "            hedges_g = calculate_hedges_g(all_aucs[i], all_aucs[j])\n",
    "            print(f\"Hedges' g for groups {i} and {j} at time bin {t_start}-{t_end} and freq bin {low_freq}-{high_freq}: {hedges_g}\")\n",
    "            # create a DataFrame to hold the Hedges' g results and store in the all_hedges_dfs list\n",
    "            df_hedges = pd.DataFrame({\n",
    "                'Group1': [group_titles[i]],\n",
    "                'Group2': [group_titles[j]],\n",
    "                'Hedges_g': [hedges_g],\n",
    "                'time_bin_start': [t_start],\n",
    "                'time_bin_end': [t_end],\n",
    "                'freq_bin_low': [low_freq],\n",
    "                'freq_bin_high': [high_freq]\n",
    "            })\n",
    "            all_hedges.append(df_hedges)    \n",
    "        \n",
    "        plot_auc(groups, avg_aucs, all_aucs, group_titles, colors, save=False, output_dir=output_dir)\n",
    "\n",
    "# all_stats_combined = pd.concat(all_stats, ignore_index=True)\n",
    "# all_hedges_combined = pd.concat(all_hedges, ignore_index=True)\n",
    "# all_stats_combined.to_csv(output_dir + 'stats.csv', index=False)\n",
    "# all_hedges_combined.to_csv(output_dir + \"hedges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_dir = pickle_save_dir\n",
    "\n",
    "# with open(pickle_dir+'RSC_FreeK0500.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK0500, file)\n",
    "# with open(pickle_dir+'RSC_FreeK0750.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK0750, file)\n",
    "# with open(pickle_dir+'RSC_FreeK1000.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK1000, file)\n",
    "# with open(pickle_dir+'RSC_FreeK1500.pkl', 'wb') as file:\n",
    "#     pickle.dump(FreeK1500, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGMRTYNWcgFhvIrwFXWopr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
